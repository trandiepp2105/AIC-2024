{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9426884,"sourceType":"datasetVersion","datasetId":5726534}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pygments pillow requests tqdm pandas opencv-python open_clip_torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nCSV_FOLDER = r\"/kaggle/working/csv\"\nFRAMES_FOLDER = r\"/kaggle/input/frames-l2-b2\"\nCSV_FPS = r\"/kaggle/input/frames-l2-b2/frames-l2-b2.csv\"\n\nBATCH_CLIP_SIZE=6144\n\nTHRESHOLD_SIMILARITY=0.85\n\nEMBEDDING_NAME='ViT-B-32-256'\nEMBEDDING_PRETRAINED='datacomp_s34b_b86k'\nEMBEDDING_TOKEN='ViT-B-32-256'\n\nEM_MODEL_2='ViT-H-14-quickgelu'\nEM_MODEL_2_PRETRAINED='dfn5b'\nEM_TOKEN_2='ViT-H-14-quickgelu'\n\nEMBEDDING_FOLDER=r\"/kaggle/working/embeddings\"\n\nEMBEDDING_BATCH_SIZE=512\n\nROOT_DIR = r\"/kaggle/temp\"","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:34:15.705090Z","iopub.execute_input":"2024-09-05T05:34:15.706140Z","iopub.status.idle":"2024-09-05T05:34:15.712444Z","shell.execute_reply.started":"2024-09-05T05:34:15.706095Z","shell.execute_reply":"2024-09-05T05:34:15.711391Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport open_clip\n\nclass CLIP_Embedding:\n    def __init__(self, model_name=\"ViT-L-14\", pretrained=\"commonpool_xl_laion_s13b_b90k\", device=\"cuda\", tokenizers='ViT-L-14'):\n        self.device = device\n        self.model, _, self.preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=self.device)\n        self.model.eval()\n        self.tokenizer = open_clip.get_tokenizer(tokenizers)\n\n    def get_image_embedding(self, image):\n        image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n        with torch.no_grad(), torch.amp.autocast('cuda'):\n            image_features = self.model.encode_image(image_input)\n        del image_input\n        return image_features[0]/image_features[0].norm()\n    \n    def get_images_embedding(self, images):\n        image_input = torch.stack([self.preprocess(image) for image in images]).to(self.device)\n        with torch.no_grad(), torch.amp.autocast('cuda'):\n            image_features = self.model.encode_image(image_input)\n        del image_input\n        return image_features/image_features.norm(dim=-1, keepdim=True)\n\n    def get_text_embedding(self, text):\n        text_input = self.tokenizer(text).to(self.device)\n        with torch.no_grad(), torch.amp.autocast('cuda'):\n            text_features = self.model.encode_text(text_input)\n        return text_features[0]/text_features[0].norm()\n    \nclass CLIPSingleton:\n    _instance = None\n    def __new__(cls, model_name=\"ViT-L-14\", pretrained=\"commonpool_xl_laion_s13b_b90k\", device=\"cuda\", tokenizers='ViT-L-14'):\n        if cls._instance is None:\n            cls._instance = CLIP_Embedding(model_name, pretrained, device, tokenizers)\n        return cls._instance\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:34:16.134526Z","iopub.execute_input":"2024-09-05T05:34:16.135403Z","iopub.status.idle":"2024-09-05T05:34:16.146885Z","shell.execute_reply.started":"2024-09-05T05:34:16.135358Z","shell.execute_reply":"2024-09-05T05:34:16.145960Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nfrom multiprocessing import Process\nimport os\nimport numpy as np\nimport pandas as pd\nfrom timeit import default_timer as timer\nimport time\n\ndef embedding_batch(list_frames, embedding_model):\n    images = [Image.open(frame) for _, frame in list_frames]\n    embeddings = embedding_model.get_images_embedding(images).detach().cpu().numpy()\n    list_embedding = [(list_frames[i][0], embeddings[i]) for i in range(len(list_frames))]\n    return list_embedding\n\ndef save_embedding(list_embedding, output_folder):\n    for frame_number, embedding in list_embedding:\n        embedding_path = os.path.join(output_folder, f'{frame_number}.npy')\n        np.save(embedding_path, embedding)\n\ndef similarity(embedding1, embedding2):\n    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n\ndef get_fps(video_name):\n    df = pd.read_csv(CSV_FPS)\n    fps = df.loc[df['video_name'] == video_name, 'fps']\n    \n    # Kiểm tra nếu tìm thấy thì trả về giá trị, ngược lại trả về None\n    if not fps.empty:\n        return fps.values[0]\n    else:\n        return 25\n\ndef get_keyframes(list_embedding, embedding_folder, csv_folder, video_name, threshold=THRESHOLD_SIMILARITY):\n    list_keyframes = {\n        'frame_number': [],\n        'second': []\n    }\n    \n    sorted\n    \n    fps = get_fps(video_name)\n\n    v_pred = None\n    keyframes_embedding = []\n    for frame_number, embedding in list_embedding:\n        if v_pred is None:\n            v_pred = embedding\n            list_keyframes['frame_number'].append(frame_number)\n            list_keyframes['second'].append(int(frame_number)/fps)\n            keyframes_embedding.append((frame_number, embedding))\n        else:\n            sim = similarity(v_pred, embedding)\n            if sim < threshold:\n                v_pred = embedding\n                list_keyframes['frame_number'].append(frame_number)\n                list_keyframes['second'].append(int(frame_number)/fps)\n                keyframes_embedding.append((frame_number, embedding))\n\n    df = pd.DataFrame(list_keyframes)\n    df.to_csv(os.path.join(csv_folder, f'{video_name}.csv'), index=False)\n#     Process(target=save_embedding, args=(keyframes_embedding, embedding_folder)).start()\n    print(f'Keyframes {video_name} done')\n    \n\ndef embedding_frame(list_frames, embedding_folder, csv_folder, embedding_model, video_name, batch_size=32):\n    output_folder = os.path.join(embedding_folder, video_name)\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    list_embedding = []\n\n    for i in range(0, len(list_frames), batch_size):\n        batch = list_frames[i:i+batch_size]\n        embeddings = embedding_batch(batch, embedding_model)\n        print(f'Embedding {i} done')\n        list_embedding.extend(embeddings)\n\n    Process(target=get_keyframes, args=(list_embedding, output_folder, csv_folder, video_name)).start()\n\n    print(f'Emedding {video_name} done')\n\ndef keyframes_to_embedding(list_keyframes, embedding_folder, embedding_model, video_name, batch_size=32):\n    output_folder = os.path.join(embedding_folder, video_name)\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    list_embedding = []\n\n    for i in range(0, len(list_keyframes), batch_size):\n        batch = list_keyframes[i:i+batch_size]\n        embeddings = embedding_batch(batch, embedding_model)\n        print(f'Embedding {i} done')\n        list_embedding.extend(embeddings)\n\n    Process(target=save_embedding, args=(list_embedding, output_folder)).start()\n\n    print(f'Emedding {video_name} done')\n\ndef get_list_keyframes(csv_path, keyframes_folder, video_name):\n    df = pd.read_csv(csv_path)\n    key_frames = df['frame_number'].values.tolist()\n\n    keyframes_f = os.path.join(keyframes_folder, video_name)\n\n    list_keyframes = []\n    for key_frame in key_frames:\n        key_frame_path = os.path.join(keyframes_f, f'{key_frame}.jpg')\n        list_keyframes.append((key_frame, key_frame_path))\n\n    return list_keyframes\n\ndef get_list_frames(frames_folder, video_name):\n    frames_folder = os.path.join(frames_folder, video_name)\n    list_frames = [(f.split('.')[0], os.path.join(frames_folder, f)) for f in os.listdir(frames_folder) if f.endswith('.jpg')]\n    list_frames.sort(key=lambda x: int(x[0]))\n    return list_frames\n\ndef create_embedding_and_csv(frames_folder, embedding_folder, csv_folder, embedding_model, video_name, batch_size):\n    list_frames = get_list_frames(frames_folder, video_name)\n    embedding_frame(list_frames, embedding_folder, csv_folder, embedding_model, video_name, batch_size)\n\ndef extract_embedding(csv_path, video_name, keyframes_folder, embedding_folder, embedding_model, batch_size):\n    list_keyframes = get_list_keyframes(csv_path, keyframes_folder, video_name)\n    keyframes_to_embedding(list_keyframes, embedding_folder, embedding_model, video_name, batch_size)\n\ndef wfile(folder, ext):\n    return [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(ext)]\n\ndef embedding_keyframes(csv_folder, keyframes_folder, embedding_folder, embedding_model, embedding_batch_size=32):\n    embedding_model = CLIP_Embedding(*embedding_model)\n    videos = wfile(csv_folder, '.csv')\n\n    for video in videos:\n        start = timer()\n        video_name = os.path.basename(video).split('.')[0]\n        csv_path = os.path.join(csv_folder, f'{video_name}.csv')\n        extract_embedding(csv_path, video_name, keyframes_folder, embedding_folder, embedding_model, embedding_batch_size)\n\n        print(f'{video_name} done in {timer() - start}')\n    del embedding_model\n    torch.cuda.empty_cache()\n\ndef frames_to_keyframes(frames_folder, csv_folder, embedding_folder, embedding_model, batch_size):\n    embedding_model = CLIP_Embedding(*embedding_model)\n    videos = [os.path.join(frames_folder, f) for f in os.listdir(frames_folder) if os.path.isdir(os.path.join(frames_folder, f))]\n\n    for video in videos:\n        start = timer()\n        video_name = os.path.basename(video)\n        create_embedding_and_csv(frames_folder, embedding_folder, csv_folder, embedding_model, video_name, batch_size)\n\n        print(f'{video_name} done in {timer() - start}')\n    del embedding_model\n    torch.cuda.empty_cache()\n\nif __name__ == '__main__':\n    embedding_model = EMBEDDING_NAME\n    embedding_pretrained = EMBEDDING_PRETRAINED\n    embedding_token = EMBEDDING_TOKEN\n    device = 'cuda'\n    embedding_batch_size_1 = BATCH_CLIP_SIZE\n    embedding_batch_size_2 = EMBEDDING_BATCH_SIZE\n\n    csv_folder = CSV_FOLDER\n    frames_folder = FRAMES_FOLDER\n    embedding_folder = EMBEDDING_FOLDER\n\n    if not os.path.exists(embedding_folder):\n        os.makedirs(embedding_folder)\n        \n    if not os.path.exists(csv_folder):\n        os.makedirs(csv_folder)\n\n    frames_to_keyframes(frames_folder, csv_folder, embedding_folder, (embedding_model, embedding_pretrained, device, embedding_token), embedding_batch_size_1)\n    time.sleep(3)\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n    time.sleep(3)\n    embedding_keyframes(csv_folder, frames_folder, embedding_folder, (EM_MODEL_2, EM_MODEL_2_PRETRAINED, device, EM_TOKEN_2), embedding_batch_size_2)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-05T05:34:16.894316Z","iopub.execute_input":"2024-09-05T05:34:16.894754Z","iopub.status.idle":"2024-09-05T05:36:05.161167Z","shell.execute_reply.started":"2024-09-05T05:34:16.894710Z","shell.execute_reply":"2024-09-05T05:36:05.159506Z"},"trusted":true},"outputs":[],"execution_count":null}]}