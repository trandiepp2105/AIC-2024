{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd AIC-2024/ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = [\n",
    "    'a',\n",
    "    'b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = r\"C:\\Users\\hokha\\OneDrive\\Desktop\\test_download\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\hokha\\OneDrive\\Desktop\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FOLDER = os.path.join(ROOT_DIR, 'embeddings')\n",
    "FRAME_FOLDER = os.path.join(ROOT_DIR, 'frames')\n",
    "VIDEO_FOLDER = os.path.join(ROOT_DIR, 'video')\n",
    "MODEL_FOLDER = os.path.join(ROOT_DIR, 'models')\n",
    "OCR_FOLDER = os.path.join(ROOT_DIR, 'ocr')\n",
    "KEYFRAME_FOLDER = os.path.join(ROOT_DIR, 'keyframes')\n",
    "DE_FOLDER = os.path.join(ROOT_DIR, 'descriptions')\n",
    "\n",
    "DE_EMBEDDING_FOLDER = os.path.join(OUTPUT_DIR, 'de_embeddings')\n",
    "OCR_EMBEDDING_FOLDER = os.path.join(OUTPUT_DIR, 'ocr_embeddings')\n",
    "OBJECT_FOLDER = os.path.join(OUTPUT_DIR, 'objects')\n",
    "FINAL_EMBEDDING_FOLDER = os.path.join(OUTPUT_DIR, 'final_embeddings')\n",
    "CSV_FOLDER = os.path.join(OUTPUT_DIR, 'csv')\n",
    "\n",
    "MODELS_CLIP_NAME='ViT-B-32'\n",
    "PRETRAINED_CLIP='datacomp_xl_s13b_b90k'\n",
    "TOKENIZER_CLIP='ViT-B-32'\n",
    "\n",
    "BATCH_CLIP_SIZE=512\n",
    "\n",
    "THRESHOLD_KEYFRAME = 0.9\n",
    "FRAME_WIDTH = 640\n",
    "FRAME_HEIGHT = 480\n",
    "\n",
    "KEYFRAME_PROCESS = 2\n",
    "\n",
    "DE_MODEL=\"Salesforce/blip-image-captioning-base\"\n",
    "DE_PROCESSOR=\"Salesforce/blip-image-captioning-base\"\n",
    "DE_BATCH_SIZE=128\n",
    "DE_EMBEDDING_BATCH_SIZE=128\n",
    "\n",
    "\n",
    "#Object detection\n",
    "MODEL_YOLOV8='yolov8m.pt'\n",
    "BATCH_SIZE_YOLO=64\n",
    "MODEL_YOLO_ROOT='/data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hokha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scripts.utils import *\n",
    "from scripts.extract_frame import *\n",
    "from scripts.image_to_text import *\n",
    "from scripts.models import *\n",
    "from scripts.description_embedding import *\n",
    "\n",
    "import os, shutil\n",
    "from object_detection import generate_output_json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def keyframe_and_embedding(frames_folder, video_folder, keyframe_folder, embedding_folder, csv_folder, threshold=1e-3, width=1024, height=1024, batch_size=32, num_processes=8):\n",
    "    print(\"Loading CLIP model...\")\n",
    "    model_name = MODELS_CLIP_NAME\n",
    "    pretrained = PRETRAINED_CLIP\n",
    "    tokenizers = TOKENIZER_CLIP\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    embedding = (model_name, pretrained, tokenizers, device)\n",
    "    print(\"Model loaded.\")\n",
    "    # Create keyframe folder\n",
    "    if not os.path.exists(keyframe_folder):\n",
    "        os.makedirs(keyframe_folder)\n",
    "    # Create embedding folder\n",
    "    if not os.path.exists(embedding_folder):\n",
    "        os.makedirs(embedding_folder)\n",
    "    \n",
    "    if not os.path.exists(csv_folder):\n",
    "        os.makedirs(csv_folder)\n",
    "    \n",
    "    if not os.path.exists(frames_folder):\n",
    "        os.makedirs(frames_folder)\n",
    "    \n",
    "    # Extract keyframes\n",
    "    # print(\"Extracting keyframes...\")\n",
    "    # extract_keyframes(video_folder, keyframe_folder, embedding_folder, embedding, threshold=threshold, width=width, height=height, batch_size=256)\n",
    "\n",
    "    # print(\"Extracting frames...\")\n",
    "    # multiprocessing_extract_from_keyframes(video_folder, keyframe_folder, frame_folder, width=width, height=height, num_processes=8)\n",
    "    \n",
    "    print(\"Extracting video...\")\n",
    "    extract_video(frames_folder, video_folder, keyframe_folder, embedding_folder, embedding, csv_folder, threshold=threshold, width=width, height=height, batch_size=batch_size, num_processes=num_processes)\n",
    "    print(\"Done.\")\n",
    "\n",
    "def object_detection(frame_folder, object_folder, models = 'yolov8m.pt', batch_size = 64, model_dir='data/models_yolo'):\n",
    "    if not os.path.exists(object_folder):\n",
    "        os.makedirs(object_folder)\n",
    "    \n",
    "    print(\"Generating output JSON Object Detection...\")\n",
    "    generate_output_json(frame_folder, object_folder, model_path=models, batch_size=batch_size, model_dir=model_dir)\n",
    "    print(\"Done.\")\n",
    "\n",
    "def description_embedding(keyframe_folder, description_folder, embedding_folder, description_model, embedding_model, description_batch_size=32, embedding_batch_size=32):\n",
    "    if not os.path.exists(embedding_folder):\n",
    "        os.makedirs(embedding_folder)\n",
    "    \n",
    "    if not os.path.exists(description_folder):\n",
    "        os.makedirs(description_folder)\n",
    "    \n",
    "    print(\"Extracting description...\")\n",
    "    extract_description_folder(keyframe_folder, description_folder, description_model, batch_size=description_batch_size)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    print(\"Embedding description...\")\n",
    "    embedding_description_folder(description_folder, embedding_folder, embedding_model, batch_size=embedding_batch_size)\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "def setup_data():\n",
    "    s = timer()\n",
    "    videos_folder = VIDEO_FOLDER\n",
    "    keyframe_folder = KEYFRAME_FOLDER\n",
    "    embedding_folder = EMBEDDING_FOLDER\n",
    "    threshold_keyframe = THRESHOLD_KEYFRAME\n",
    "    csv_folder = CSV_FOLDER\n",
    "    frames_folder = FRAME_FOLDER\n",
    "\n",
    "    batch_extract = BATCH_CLIP_SIZE\n",
    "\n",
    "    width = FRAME_WIDTH\n",
    "    height = FRAME_HEIGHT\n",
    "    start = timer()\n",
    "\n",
    "    num_process = KEYFRAME_PROCESS\n",
    "    keyframe_and_embedding(frames_folder, videos_folder, keyframe_folder, embedding_folder, csv_folder, threshold=threshold_keyframe, width=width, height=height, batch_size=batch_extract, num_processes=num_process)\n",
    "    print(\"Time to extract keyframes and embeddings: \", timer()-start)\n",
    "\n",
    "    description_name = DE_MODEL\n",
    "    description_pretrained = DE_PROCESSOR\n",
    "    embedding_name = MODELS_CLIP_NAME\n",
    "    embedding_pretrained = PRETRAINED_CLIP\n",
    "    tokenizer_name = TOKENIZER_CLIP\n",
    "    description_folder = DE_FOLDER\n",
    "    de_embedding_folder = DE_EMBEDDING_FOLDER\n",
    "    description_batch = DE_BATCH_SIZE\n",
    "    de_embedding_batch = DE_EMBEDDING_BATCH_SIZE\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    start = timer()\n",
    "    description_embedding(keyframe_folder, description_folder, de_embedding_folder, (description_name, description_pretrained, device), (embedding_name, embedding_pretrained, tokenizer_name, device), description_batch_size=description_batch, embedding_batch_size=de_embedding_batch)\n",
    "    print(\"Time to extract description and embeddings: \", timer()-start)\n",
    "\n",
    "    object_folder = OBJECT_FOLDER\n",
    "    batch_object = BATCH_SIZE_YOLO\n",
    "    yolo_root = MODEL_YOLO_ROOT\n",
    "    yolo_model = MODEL_YOLOV8\n",
    "    start = timer()\n",
    "    object_detection(keyframe_folder, object_folder, models=yolo_model, batch_size=batch_object, model_dir=yolo_root)\n",
    "    print(\"Time to extract objects: \", timer()-start)\n",
    "\n",
    "    print(\"Total time: \", timer()-s)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_file(url, filename, output_dir):\n",
    "    path = os.path.join(output_dir, filename)\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "def unzip_file(file_path, output_dir):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "\n",
    "    os.remove(file_path)\n",
    "\n",
    "def download_and_unzip(url, filename, output_dir):\n",
    "    download_file(url, filename, output_dir)\n",
    "    unzip_file(os.path.join(output_dir, filename), output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_in_folder(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data a\n",
      "Data a downloaded\n",
      "Setting up data...\n",
      "Loading CLIP model...\n",
      "Model loaded.\n",
      "Extracting video...\n"
     ]
    }
   ],
   "source": [
    "for data in list_data:\n",
    "    print(f\"Downloading data {data}\")\n",
    "    # download_and_unzip(f\"https://storage.googleapis.com/quickgelu/{data}.zip\", f\"{data}.zip\", ROOT_DIR)\n",
    "    print(f\"Data {data} downloaded\")\n",
    "\n",
    "    print(\"Setting up data...\")\n",
    "    setup_data()\n",
    "    print(\"Data setup done\")\n",
    "\n",
    "    print(f\"Removing data {data}\")\n",
    "    remove_all_in_folder(ROOT_DIR)\n",
    "    print(f\"Data {data} removed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
